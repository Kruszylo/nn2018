{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to RNNs\n",
    "\n",
    "Goal of the lab is to:\n",
    "    * Implement a simple RNN\n",
    "    * Understand vanishing gradients in RNNs\n",
    "    * Revisit code conventions: PyTorch data loader, functional model construction, more standard trainig loop\n",
    "    \n",
    "References:\n",
    "    * Content heavily based on https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents-notebooks/402_RNN.ipynb (I highly recommend the whole repository)\n",
    "    * http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whiteboard exercises\n",
    "\n",
    "(Plus any left out exercise from the previous labs)\n",
    "\n",
    "<img width=500 src=\"http://www.wildml.com/wp-content/uploads/2015/10/rnn-bptt-with-gradients.png\">\n",
    "\n",
    "* (0.5) Find  in literature at least two ways to combat vanishing gradients in RNNs *without* changing the architecture. Describe them and argue why they should work. \n",
    "\n",
    "* (0.5) Describe how Truncated Back Propagation Through Time (TBPTT) would work for the network in the figure. Argue why TBPTT, with a correctly chosen cutoff, can be an effective method (e.g. not leading to inaccurate gradients and not slowing convergence) of training?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(1)\n",
    "def orthogonal(tensor, gain=1):\n",
    "    # Code adapted from https://github.com/alykhantejani/nninit/blob/master/nninit.py\n",
    "    if isinstance(tensor, Variable):\n",
    "        orthogonal(tensor.data, gain=gain)\n",
    "        return tensor\n",
    "    else:\n",
    "        if tensor.ndimension() < 2:\n",
    "            raise ValueError(\"Only tensors with 2 or more dimensions are supported.\")\n",
    "\n",
    "        flattened_shape = (tensor.size(0), int(np.prod(tensor.numpy().shape[1:])))\n",
    "        flattened = torch.Tensor(flattened_shape[0], flattened_shape[1]).normal_(0, 1)\n",
    "\n",
    "        u, s, v = np.linalg.svd(flattened.numpy(), full_matrices=False)\n",
    "        if u.shape == flattened.numpy().shape:\n",
    "            tensor.view_as(flattened).copy_(torch.from_numpy(u))\n",
    "        else:\n",
    "            tensor.view_as(flattened).copy_(torch.from_numpy(v))\n",
    "\n",
    "        tensor.mul_(gain)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters (constant for the notebook)\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "TIME_STEP = 28          # rnn time step / image height\n",
    "INPUT_SIZE = 28         # rnn input size / image width\n",
    "LR = 0.01               # learning rate\n",
    "DOWNLOAD_MNIST = True   # set to True if haven't download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_rebuild_tensor_v2' on <module 'torch._utils' from 'C:\\\\Users\\\\Maxim\\\\Anaconda3\\\\lib\\\\site-packages\\\\torch\\\\_utils.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-36f9b64cfabf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[1;31m# Converts a PIL.Image or numpy.ndarray to\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                         \u001b[1;31m# torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m            \u001b[1;31m# download it if you don't have it\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             self.train_data, self.train_labels = torch.load(\n\u001b[1;32m---> 54\u001b[1;33m                 os.path.join(self.root, self.processed_folder, self.training_file))\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             self.test_data, self.test_labels = torch.load(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute '_rebuild_tensor_v2' on <module 'torch._utils' from 'C:\\\\Users\\\\Maxim\\\\Anaconda3\\\\lib\\\\site-packages\\\\torch\\\\_utils.py'>"
     ]
    }
   ],
   "source": [
    "# A standard way to load a dataset\n",
    "train_data = dsets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                         # this is training data\n",
    "    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,            # download it if you don't have it\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# convert test data into Variable, pick 2000 samples to speed up testing\n",
    "test_data = dsets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor())\n",
    "# shape (2000, 28, 28) value in range(0,1)\n",
    "test_x = Variable(test_data.test_data, volatile=True).type(torch.FloatTensor)[:2000]/255.   \n",
    "test_y = test_data.test_labels.numpy().squeeze()[:2000]    # covert to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Code your own RNN\n",
    "\n",
    "Code your own RNN. It will be defined by two layers:\n",
    "\n",
    "* i2h: takes *input and hidden state from the previous step* and *produce new hidden state* using equation $$h_{t+1}=tanh(W input_{t+1} + U h_{t})$$\n",
    "\n",
    "* h2o: taken hidden state and produces $$o_{t+1} = softmax(Vh_{t+1})$$ (note that in pytorch softmax is applied within the cross entropy loss function)\n",
    "\n",
    "Tasks:\n",
    "\n",
    "* Fill up missing blanks to train your own RNN!\n",
    "* Save results as a figure (10a_1.png)\n",
    "\n",
    "Starting code is provided.\n",
    "\n",
    "Expected outcome:\n",
    "\n",
    "<img width=300 src=\"https://raw.githubusercontent.com/gmum/nn2018/master/lab/fig/10/ex1_expected.png\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, init_strategy=\"simple\", init_scale=0.01):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear((input_size + hidden_size), hidden_size) ## Hint: linear module, from (input size + hidden_size) to hidden_size\n",
    "        self.h2o = nn.Linear(hidden_size, output_size) # Hint: linear module\n",
    "        \n",
    "        if init_strategy == \"simple\":\n",
    "            self.i2h.weight.data.normal_(0, init_scale)\n",
    "        elif init_strategy == \"orth\":\n",
    "            orthogonal(self.i2h.weight)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        self.i2h.bias.data.fill_(0)\n",
    "        self.h2o.weight.data.uniform_(0, init_scale)\n",
    "        self.h2o.bias.data.fill_(0)\n",
    "            \n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1) # Hint: use torch.cat to combine input and hidden input 2d vector\n",
    "        hidden = F.tanh(self.i2h(combined)) # Hint: use input to hidden\n",
    "        output = (self.h2o(hidden)) # Hint: use hidden to output\n",
    "        return output, hidden\n",
    "    \n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return Variable(torch.zeros(batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(28, 64, 10)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing\n",
    "H = {\"acc\": []}\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):        # gives batch data\n",
    "        b_x = Variable(x.view(-1, 28, 28))              # reshape x to (batch, time_step, input_size)\n",
    "        b_y = Variable(y)                               # batch y\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        hidden = rnn.initHidden(b_x.size()[0])\n",
    "        for i in range(b_x.size()[1]): # Hint: iterate through all the steps\n",
    "            output, hidden = rnn.forward(b_x[:,i,:], hidden) # Hint: just apply forward from the model\n",
    "        loss = loss_func(output, b_y)\n",
    "        \n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            hidden = rnn.initHidden(test_x.size()[0])\n",
    "            for i in range(test_x.size()[1]):\n",
    "                test_output, hidden = rnn(test_x[:, i], hidden)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "            accuracy = sum(pred_y == test_y.reshape(-1,)) / float(test_y.size)\n",
    "            H['acc'].append(accuracy)\n",
    "            print('Epoch: ', epoch + step*len(b_x)/2000., '| train loss: %.4f' % loss.data[0], '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Simple(0.01)\")\n",
    "plt.plot(H['acc'])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training accuracy\")\n",
    "plt.savefig(\"10a_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Vanishing Gradient\n",
    "\n",
    "\n",
    "* Measure ||dL/dh_i|| for different states, where ||.|| is the euclidean norm of the vector. \n",
    "* Compare the orthonomal (with scale=0.01) and simple (with scale=0.001). Save figures (10a_2_simple.png, 10a_2_orth.png)\n",
    "\n",
    "Starting code is provided\n",
    "\n",
    "Expected outcome (x axis is epoch, y axis is ||dL/dh_i||, color is index):\n",
    "\n",
    "<img width=300 src=\"https://raw.githubusercontent.com/gmum/nn2018/master/lab/fig/10/ex2_expected_simple.png\"> \n",
    "<img width=300 src=\"https://raw.githubusercontent.com/gmum/nn2018/master/lab/fig/10/ex2_expected_orth.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = defaultdict(list)\n",
    "\n",
    "rnn = RNN(28, 64, 10, \"simple\", 0.001)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "    \n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):        # gives batch data\n",
    "        b_x = Variable(x.view(-1, 28, 28))              # reshape x to (batch, time_step, input_size)\n",
    "        b_y = Variable(y)                               # batch y\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make sure gradients are retained\n",
    "        hidden = rnn.initHidden(b_x.size()[0])\n",
    "        hiddens = [hidden]\n",
    "        for i in range(b_x.size()[1]): # Hint: iterate through all the steps\n",
    "            output, hidden = rnn.forward(b_x[:,i,:], hidden) # Hint: just apply forward from the model\n",
    "            hiddens.append(hidden)\n",
    "            hidden.retain_grad() # google \"retain_grad\". Otherwise hidden.grad=None. \n",
    "        loss = loss_func(output, b_y)\n",
    "        \n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward(retain_variables=True)      # backpropagation, compute gradients\n",
    "        \n",
    "        # Save ||dL/dh_i||\n",
    "        dLdhi = []\n",
    "        for h in hiddens:\n",
    "            g = h.grad.data.numpy()\n",
    "            dLdhi.append(np.linalg.norm(g)) # Hint: Just compute ||dL/dh_i|| from h.grad.data.numpy() using np.linalg.norm + average over examples\n",
    "        \n",
    "        optimizer.step()                                \n",
    "\n",
    "        if step % 50 == 0:\n",
    "            hidden = rnn.initHidden(test_x.size()[0])\n",
    "            for i in range(test_x.size()[1]):\n",
    "                test_output, hidden = rnn(test_x[:, i], hidden)\n",
    "            \n",
    "            for i, val in enumerate(dLdhi):\n",
    "                H['dL/dh_{}'.format(i)].append(val)\n",
    "                \n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "            accuracy = sum(pred_y == test_y.reshape(-1,)) / float(test_y.size)\n",
    "            H['acc'].append(accuracy)\n",
    "            print('Epoch: ', epoch + step*len(b_x)/2000., '| train loss: %.4f' % loss.data[0], '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "cm = plt.get_cmap(\"coolwarm\", 80)\n",
    "plt.title(\"Simple(0.01)\") \n",
    "for i in range(28):\n",
    "    plt.plot(H['dL/dh_{}'.format(i)], color=cm(i/28.))\n",
    "plt.savefig(\"10a_2_simple.png\") # Change to 2_orth.png for orthonormal run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
