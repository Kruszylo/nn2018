{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RNNs: LSTM\n",
    "\n",
    "Goal of the lab is to:\n",
    "    * Understand and implement parts of LSTM\n",
    "    \n",
    "References:\n",
    "    * http://colah.github.io/posts/2015-08-Understanding-LSTMs/ (good ref. for the general equations)\n",
    "    * https://ytd2525.wordpress.com/2016/08/03/understanding-deriving-and-extending-the-lstm/ (more in depth journey through LSTM variants)\n",
    "    * http://nicodjimenez.github.io/2014/08/08/lstm.html (explains well constant error carousel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whiteboard exercises\n",
    "\n",
    "(Any left out exercise from the previous labs)\n",
    "\n",
    "* (0.5) Describe the main difference between GRU and LSTM. What is the intuition behind GRU? \n",
    "\n",
    "* (0.5) Describe the peephole connection variant of LSTM. What is the intuition behind peephole connection?\n",
    "\n",
    "* (0.5) Describe what is the \"shadow state\" in LSTM. See: https://ytd2525.wordpress.com/2016/08/03/understanding-deriving-and-extending-the-lstm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import torch\n",
    "from torch.nn import Module, Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline\n",
    "import json\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters (constant for the notebook)\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "TIME_STEP = 28          # rnn time step / image height\n",
    "INPUT_SIZE = 28         # rnn input size / image width\n",
    "LR = 0.01               # learning rate\n",
    "DOWNLOAD_MNIST = True   # set to True if haven't download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# A standard way to load a dataset\n",
    "train_data = dsets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                         # this is training data\n",
    "    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,            # download it if you don't have it\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# convert test data into Variable, pick 2000 samples to speed up testing\n",
    "test_data = dsets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor())\n",
    "# shape (2000, 28, 28) value in range(0,1)\n",
    "test_x = Variable(test_data.test_data, volatile=True).type(torch.FloatTensor)[:2000]/255.   \n",
    "test_y = test_data.test_labels.numpy().squeeze()[:2000]    # covert to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Code LSTM\n",
    "\n",
    "Reference: http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "Fill in the missing blanks. Train a single epoch, and save a plot of accuracy to ``10b_ex1.png``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Note: parameters are initialized for you, but feel free to change this\n",
    "        # the suggested way of implementing forward is computing all inputs to\n",
    "        # gates at once by using a D -> 4*D linear layer\n",
    "        self.weight_ih = Parameter(torch.Tensor(4 * hidden_size, input_size))\n",
    "        self.weight_hh = Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(4 * hidden_size))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, hx):\n",
    "        h, c = hx\n",
    "\n",
    "        # Compute input (i), forget (f), g (marked as \\tilde{C_t} in Colah), output (o),\n",
    "        # state (c) and hidden state (h)\n",
    "        # For reference see http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "        #m1 = torch.cat( \n",
    "        #                        (self.weight_ih[:self.hidden_size,:], \n",
    "        #                        self.weight_hh[:self.hidden_size,:]),1\n",
    "        #                        )\n",
    "        #m2 = torch.cat((h,input),1).transpose(0,1)\n",
    "        #print(h.t().size(),input.t().size(),self.bias.size())\n",
    "        i = F.sigmoid( torch.mm(self.weight_ih[:self.hidden_size,:], input.t()) + torch.mm(self.weight_hh[:self.hidden_size,:], h.t()) + self.bias[0] )\n",
    "        f = F.sigmoid( \n",
    "                \n",
    "                        torch.mm(self.weight_ih[self.hidden_size:self.hidden_size*2,:], input.t()) + \n",
    "                                torch.mm(self.weight_hh[self.hidden_size:self.hidden_size*2,:],h.t())\n",
    "                                 + self.bias[1]  \n",
    "                                )\n",
    "        o = F.sigmoid( \n",
    "                \n",
    "                        torch.mm(self.weight_ih[self.hidden_size*2:self.hidden_size*3,:], input.t()) + \n",
    "                                torch.mm(self.weight_hh[self.hidden_size*2:self.hidden_size*3,:],h.t())\n",
    "                                 + self.bias[2]\n",
    "                                )\n",
    "        g = F.tanh( \n",
    "                \n",
    "                        torch.mm(self.weight_ih[self.hidden_size*3:self.hidden_size*4,:], input.t()) + \n",
    "                                torch.mm(self.weight_hh[self.hidden_size*3:self.hidden_size*4,:],h.t())\n",
    "                                 + self.bias[3] \n",
    "                                )\n",
    "        c = f*c.t() + i*g #f*c_t-1 + i*g\n",
    "        h = (o * F.tanh( c.t() ).t()).t()\n",
    "        return h, c.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, recurrent_size=None, bias=True, \n",
    "                 return_sequences=True, grad_clip=None):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.recurrent_size = recurrent_size\n",
    "        self.bias = bias\n",
    "        self.return_sequences = return_sequences\n",
    "        self.grad_clip = grad_clip\n",
    "\n",
    "        Cell = LSTMCell\n",
    "\n",
    "        kwargs = {'input_size': input_size,\n",
    "                  'hidden_size': hidden_size,\n",
    "                  'bias': bias}\n",
    "\n",
    "        self.cell0 = Cell(**kwargs)\n",
    "        \n",
    "    def forward(self, input, initial_states=None):\n",
    "        if initial_states is None:\n",
    "            zeros = Variable(torch.zeros(input.size(0), self.hidden_size))\n",
    "            initial_states = [(zeros, zeros), ]\n",
    "\n",
    "        states = initial_states\n",
    "        outputs = []\n",
    "\n",
    "        # Note: Similar to code we wrote in 10a_rnn.\n",
    "        \n",
    "        time_steps = input.size(1)\n",
    "        for t in range(time_steps):\n",
    "            x = input[:, t, :]\n",
    "            hx = self.cell0(x, states[0])\n",
    "            states[0] = hx\n",
    "            x = hx[0]\n",
    "            outputs.append(hx)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            hs, cs = zip(*outputs)\n",
    "            h = torch.stack(hs).transpose(0, 1)\n",
    "            c = torch.stack(cs).transpose(0, 1)\n",
    "            output = (h, c)\n",
    "        else:\n",
    "            output = outputs[-1]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = LSTM(28, 64, return_sequences=False)\n",
    "clf = nn.Linear(64, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.3077 | test accuracy: 0.10\n",
      "train loss: 1.7221 | test accuracy: 0.50\n",
      "train loss: 1.3488 | test accuracy: 0.58\n",
      "train loss: 1.0095 | test accuracy: 0.71\n",
      "train loss: 0.8650 | test accuracy: 0.75\n",
      "train loss: 0.7425 | test accuracy: 0.84\n",
      "train loss: 0.8469 | test accuracy: 0.86\n",
      "train loss: 0.5916 | test accuracy: 0.88\n",
      "train loss: 0.4832 | test accuracy: 0.88\n",
      "train loss: 0.4793 | test accuracy: 0.88\n",
      "train loss: 0.3821 | test accuracy: 0.87\n",
      "train loss: 0.6930 | test accuracy: 0.87\n",
      "train loss: 0.5915 | test accuracy: 0.90\n",
      "train loss: 0.3929 | test accuracy: 0.86\n",
      "train loss: 0.6591 | test accuracy: 0.91\n",
      "train loss: 0.4942 | test accuracy: 0.92\n",
      "train loss: 0.5588 | test accuracy: 0.92\n",
      "train loss: 0.4487 | test accuracy: 0.90\n",
      "train loss: 0.4579 | test accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "# training and testing\n",
    "H = {\"acc\": []}\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):        # gives batch data\n",
    "        b_x = Variable(x.view(-1, 28, 28))              # reshape x to (batch, time_step, input_size)\n",
    "        b_y = Variable(y)                               # batch y\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        hidden, state = rnn.forward(b_x)\n",
    "        output = clf.forward(hidden)\n",
    "        loss = loss_func(output, b_y)\n",
    "        \n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            hidden, state = rnn.forward(test_x)\n",
    "            test_output = clf.forward(hidden)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "            accuracy = sum(pred_y == test_y.reshape(-1,)) / float(test_y.size)\n",
    "            H['acc'].append(accuracy)\n",
    "            print('train loss: %.4f' % loss.data[0], '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2f342e3588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"LSTM\")\n",
    "plt.plot(H['acc'])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training accuracy\")\n",
    "plt.savefig(\"10b_ex1.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
